# è…¾è®¯äº‘è½»é‡åº”ç”¨æœåŠ¡å™¨ Lighthouse éƒ¨ç½²æŒ‡å—

æœ¬æŒ‡å—ä¸“ä¸ºå°è§„æ¨¡ä¸šåŠ¡éªŒè¯é˜¶æ®µè®¾è®¡ï¼Œä½¿ç”¨è…¾è®¯äº‘è½»é‡åº”ç”¨æœåŠ¡å™¨ Lighthouse è¿›è¡Œå¿«é€Ÿã€ä½æˆæœ¬éƒ¨ç½²ã€‚

## ğŸŒŸ Lighthouse ä¼˜åŠ¿

### ç›¸æ¯”ä¼ ç»ŸCVMçš„ä¼˜åŠ¿
- **æˆæœ¬æ›´ä½**: å¥—é¤ä»·æ ¼åŒ…å«å¸¦å®½ï¼Œæ€§ä»·æ¯”æ›´é«˜
- **é…ç½®ç®€å•**: é¢„è£…åº”ç”¨æ¨¡æ¿ï¼Œä¸€é”®éƒ¨ç½²
- **ç®¡ç†æ–¹ä¾¿**: é›†æˆé˜²ç«å¢™ã€ç›‘æ§ã€å¿«ç…§ç­‰åŠŸèƒ½
- **å¿«é€Ÿå¯åŠ¨**: ç§’çº§åˆ›å»ºï¼Œå³å¼€å³ç”¨
- **é€‚åˆå°è§„æ¨¡**: ä¸“ä¸ºè½»é‡åº”ç”¨è®¾è®¡

### é€‚ç”¨åœºæ™¯
- âœ… ä¸šåŠ¡éªŒè¯é˜¶æ®µ
- âœ… å°å‹é¡¹ç›®éƒ¨ç½²
- âœ… å¼€å‘æµ‹è¯•ç¯å¢ƒ
- âœ… ä¸ªäººé¡¹ç›®
- âœ… MVPäº§å“éªŒè¯

## ğŸ—ï¸ Lighthouse æ¶æ„è®¾è®¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    è…¾è®¯äº‘ Lighthouse æ¶æ„                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  è½»é‡åº”ç”¨æœåŠ¡å™¨ (2æ ¸4GB)                                   â”‚
â”‚    â”œâ”€â”€ Docker å®¹å™¨åŒ–éƒ¨ç½²                                   â”‚
â”‚    â”œâ”€â”€ Nginx (å‰ç«¯ + åå‘ä»£ç†)                             â”‚
â”‚    â”œâ”€â”€ FastAPI åç«¯æœåŠ¡                                    â”‚
â”‚    â”œâ”€â”€ PostgreSQL (æœ¬åœ°æ•°æ®åº“)                             â”‚
â”‚    â””â”€â”€ Redis (æœ¬åœ°ç¼“å­˜)                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  è…¾è®¯äº‘æœåŠ¡é›†æˆ                                             â”‚
â”‚    â”œâ”€â”€ COS å¯¹è±¡å­˜å‚¨ (æ–‡ä»¶å­˜å‚¨)                             â”‚
â”‚    â”œâ”€â”€ OCR æ–‡å­—è¯†åˆ«                                        â”‚
â”‚    â””â”€â”€ ASR è¯­éŸ³è¯†åˆ«                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  åŸŸåå’ŒSSL                                                  â”‚
â”‚    â”œâ”€â”€ å…è´¹åŸŸåæˆ–è‡ªæœ‰åŸŸå                                   â”‚
â”‚    â””â”€â”€ Let's Encrypt å…è´¹SSLè¯ä¹¦                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ’° æˆæœ¬å¯¹æ¯”åˆ†æ

### Lighthouse vs CVM æˆæœ¬å¯¹æ¯” (æœˆåº¦)

| é¡¹ç›® | Lighthouseæ–¹æ¡ˆ | CVMæ–¹æ¡ˆ | èŠ‚çœ |
|------|---------------|---------|------|
| æœåŠ¡å™¨ | Â¥24-45 (2æ ¸4GB) | Â¥200-300 (4æ ¸8GB) | Â¥175-255 |
| æ•°æ®åº“ | Â¥0 (æœ¬åœ°éƒ¨ç½²) | Â¥150-250 (äº‘æ•°æ®åº“) | Â¥150-250 |
| Redis | Â¥0 (æœ¬åœ°éƒ¨ç½²) | Â¥50-100 (äº‘Redis) | Â¥50-100 |
| å¸¦å®½ | Â¥0 (åŒ…å«) | Â¥50-100 | Â¥50-100 |
| **æ€»è®¡** | **Â¥24-45** | **Â¥450-750** | **Â¥425-705** |

**æˆæœ¬èŠ‚çœ**: çº¦ **90%** çš„æˆæœ¬èŠ‚çœï¼

## ğŸš€ å¿«é€Ÿéƒ¨ç½²æ­¥éª¤

### ç¬¬ä¸€æ­¥ï¼šåˆ›å»º Lighthouse å®ä¾‹

#### æ¨èé…ç½®
```
å¥—é¤: é€šç”¨å‹ 2æ ¸4GB 80GB SSD
ç³»ç»Ÿ: Ubuntu 20.04 LTS
å¸¦å®½: 4Mbps (åŒ…å«)
æµé‡: 300GB/æœˆ
ä»·æ ¼: Â¥45/æœˆ (å¹´ä»˜Â¥24/æœˆ)
```

#### é€šè¿‡æ§åˆ¶å°åˆ›å»º
1. ç™»å½•è…¾è®¯äº‘æ§åˆ¶å°
2. è¿›å…¥"è½»é‡åº”ç”¨æœåŠ¡å™¨"
3. é€‰æ‹©"è‡ªå®šä¹‰é…ç½®"
4. é…ç½®å®ä¾‹å‚æ•°
5. è®¾ç½®å¯†ç å¹¶åˆ›å»º

#### é€šè¿‡CLIåˆ›å»º
```bash
# å®‰è£…è…¾è®¯äº‘CLI
pip install tccli

# é…ç½®CLI
tccli configure set secretId your-secret-id
tccli configure set secretKey your-secret-key
tccli configure set region ap-beijing

# åˆ›å»ºLighthouseå®ä¾‹
tccli lighthouse CreateInstances \
    --region ap-beijing \
    --bundleid bundle_ent_linux_02 \
    --period 1 \
    --instancecount 1 \
    --instancenames "targetmanage-lighthouse" \
    --loginpassword "YourPassword123!"
```

### ç¬¬äºŒæ­¥ï¼šé…ç½®é˜²ç«å¢™è§„åˆ™

```bash
# å¼€æ”¾å¿…è¦ç«¯å£
# HTTP: 80
# HTTPS: 443
# SSH: 22
# è‡ªå®šä¹‰åº”ç”¨ç«¯å£: 8000 (ä»…å¼€å‘è°ƒè¯•ç”¨)
```

### ç¬¬ä¸‰æ­¥ï¼šè¿æ¥æœåŠ¡å™¨å¹¶åˆå§‹åŒ–

```bash
# SSHè¿æ¥æœåŠ¡å™¨
ssh root@your-lighthouse-ip

# è¿è¡Œåˆå§‹åŒ–è„šæœ¬
curl -fsSL https://raw.githubusercontent.com/your-repo/targetmanage/main/scripts/lighthouse/setup-lighthouse.sh | bash
```

## ğŸ“¦ Lighthouse ä¸“ç”¨éƒ¨ç½²é…ç½®

### Docker Compose è½»é‡é…ç½®

åˆ›å»º `docker-compose.lighthouse.yml`ï¼š

```yaml
version: '3.8'

services:
  # PostgreSQL æ•°æ®åº“ (æœ¬åœ°éƒ¨ç½²)
  postgres:
    image: postgres:13-alpine
    container_name: targetmanage_postgres_lighthouse
    environment:
      POSTGRES_DB: targetmanage
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init-db.sql:/docker-entrypoint-initdb.d/init-db.sql
    restart: unless-stopped
    # èµ„æºé™åˆ¶
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  # Redis ç¼“å­˜ (æœ¬åœ°éƒ¨ç½²)
  redis:
    image: redis:7-alpine
    container_name: targetmanage_redis_lighthouse
    command: redis-server --maxmemory 128mb --maxmemory-policy allkeys-lru
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 128M

  # Pythonåç«¯æœåŠ¡
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile.lighthouse
    container_name: targetmanage_backend_lighthouse
    environment:
      - DATABASE_URL=postgresql://postgres:${DB_PASSWORD}@postgres:5432/targetmanage
      - REDIS_URL=redis://redis:6379/0
      - DEBUG=False
      - TENCENT_SECRET_ID=${TENCENT_SECRET_ID}
      - TENCENT_SECRET_KEY=${TENCENT_SECRET_KEY}
      - SECRET_KEY=${SECRET_KEY}
    ports:
      - "8000:8000"
    volumes:
      - ./logs:/app/logs
      - ./uploads:/app/uploads
    depends_on:
      - postgres
      - redis
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  # å‰ç«¯æœåŠ¡
  frontend:
    build:
      context: ./admin-frontend
      dockerfile: Dockerfile.lighthouse
    container_name: targetmanage_frontend_lighthouse
    ports:
      - "3000:80"
    depends_on:
      - backend
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 256M

  # Nginx åå‘ä»£ç†
  nginx:
    image: nginx:alpine
    container_name: targetmanage_nginx_lighthouse
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.lighthouse.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
      - ./uploads:/var/www/uploads
    depends_on:
      - backend
      - frontend
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 128M

volumes:
  postgres_data:
  redis_data:
```

### è½»é‡åŒ– Dockerfile

åˆ›å»º `backend/Dockerfile.lighthouse`ï¼š

```dockerfile
# è½»é‡åŒ–Pythonåç«¯Dockerfile
FROM python:3.11-slim

WORKDIR /app

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    PIP_NO_CACHE_DIR=1

# å®‰è£…ç³»ç»Ÿä¾èµ– (æœ€å°åŒ–)
RUN apt-get update && apt-get install -y \
    gcc \
    libpq-dev \
    curl \
    && rm -rf /var/lib/apt/lists/*

# å®‰è£…Pythonä¾èµ–
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# åˆ›å»ºç›®å½•
RUN mkdir -p uploads logs

# érootç”¨æˆ·
RUN adduser --disabled-password --gecos '' appuser && \
    chown -R appuser:appuser /app
USER appuser

EXPOSE 8000

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=60s --timeout=10s --start-period=20s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "2"]
```

### å‰ç«¯è½»é‡åŒ–é…ç½®

åˆ›å»º `admin-frontend/Dockerfile.lighthouse`ï¼š

```dockerfile
# è½»é‡åŒ–å‰ç«¯Dockerfile
FROM node:18-alpine AS builder

WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production --no-audit
COPY . .
RUN npm run build

# ç”Ÿäº§é˜¶æ®µ - ä½¿ç”¨æ›´å°çš„nginxé•œåƒ
FROM nginx:alpine
COPY --from=builder /app/dist /usr/share/nginx/html
COPY nginx.lighthouse.conf /etc/nginx/conf.d/default.conf
EXPOSE 80
CMD ["nginx", "-g", "daemon off;"]
```

## ğŸ› ï¸ Lighthouse ä¸“ç”¨è„šæœ¬

### æœåŠ¡å™¨åˆå§‹åŒ–è„šæœ¬

åˆ›å»º `scripts/lighthouse/setup-lighthouse.sh`ï¼š

```bash
#!/bin/bash
# Lighthouse æœåŠ¡å™¨åˆå§‹åŒ–è„šæœ¬

set -e

GREEN='\033[0;32m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
NC='\033[0m'

log_info() {
    echo -e "${GREEN}[INFO]${NC} $1"
}

log_warn() {
    echo -e "${YELLOW}[WARN]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# æ›´æ–°ç³»ç»Ÿ
update_system() {
    log_info "æ›´æ–°ç³»ç»Ÿ..."
    apt update && apt upgrade -y
}

# å®‰è£…åŸºç¡€è½¯ä»¶
install_basics() {
    log_info "å®‰è£…åŸºç¡€è½¯ä»¶..."
    apt install -y curl wget git vim htop tree unzip
}

# å®‰è£…Docker (è½»é‡ç‰ˆ)
install_docker() {
    log_info "å®‰è£…Docker..."
    curl -fsSL https://get.docker.com -o get-docker.sh
    sh get-docker.sh
    usermod -aG docker $USER
    
    # å®‰è£…Docker Compose
    curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
    chmod +x /usr/local/bin/docker-compose
}

# é…ç½®é˜²ç«å¢™ (Lighthouse å†…ç½®)
configure_firewall() {
    log_info "é…ç½®é˜²ç«å¢™..."
    # Lighthouse ä½¿ç”¨æ§åˆ¶å°é…ç½®é˜²ç«å¢™ï¼Œè¿™é‡ŒåªåšåŸºç¡€é…ç½®
    ufw --force enable
    ufw allow ssh
    ufw allow 80/tcp
    ufw allow 443/tcp
}

# åˆ›å»ºåº”ç”¨ç›®å½•
create_directories() {
    log_info "åˆ›å»ºåº”ç”¨ç›®å½•..."
    mkdir -p /opt/targetmanage/{logs,uploads,backups,nginx/ssl}
    chown -R $USER:$USER /opt/targetmanage
}

# ä¼˜åŒ–ç³»ç»Ÿ (è½»é‡åŒ–)
optimize_system() {
    log_info "ä¼˜åŒ–ç³»ç»Ÿé…ç½®..."
    
    # åŸºç¡€ä¼˜åŒ–
    cat >> /etc/sysctl.conf << EOF
# è½»é‡æœåŠ¡å™¨ä¼˜åŒ–
vm.swappiness = 10
net.core.rmem_max = 8388608
net.core.wmem_max = 8388608
EOF
    
    sysctl -p
}

# å®‰è£…ç›‘æ§å·¥å…· (è½»é‡ç‰ˆ)
install_monitoring() {
    log_info "å®‰è£…ç›‘æ§å·¥å…·..."
    apt install -y htop iotop
}

# é…ç½®è‡ªåŠ¨å¤‡ä»½
setup_backup() {
    log_info "é…ç½®å¤‡ä»½è„šæœ¬..."
    
    cat > /opt/targetmanage/backup.sh << 'EOF'
#!/bin/bash
# è½»é‡æ•°æ®åº“å¤‡ä»½è„šæœ¬
BACKUP_DIR="/opt/targetmanage/backups"
DATE=$(date +%Y%m%d_%H%M%S)

mkdir -p $BACKUP_DIR

# å¤‡ä»½PostgreSQL
docker exec targetmanage_postgres_lighthouse pg_dump -U postgres targetmanage > "$BACKUP_DIR/db_$DATE.sql"
gzip "$BACKUP_DIR/db_$DATE.sql"

# åˆ é™¤7å¤©å‰çš„å¤‡ä»½
find "$BACKUP_DIR" -name "*.sql.gz" -mtime +7 -delete

echo "Backup completed: db_$DATE.sql.gz"
EOF
    
    chmod +x /opt/targetmanage/backup.sh
    
    # æ·»åŠ å®šæ—¶ä»»åŠ¡ (æ¯å¤©å‡Œæ™¨3ç‚¹)
    (crontab -l 2>/dev/null; echo "0 3 * * * /opt/targetmanage/backup.sh") | crontab -
}

# ä¸»å‡½æ•°
main() {
    log_info "ğŸš€ å¼€å§‹åˆå§‹åŒ– Lighthouse æœåŠ¡å™¨..."
    
    if [ "$EUID" -ne 0 ]; then
        log_error "è¯·ä½¿ç”¨rootç”¨æˆ·è¿è¡Œæ­¤è„šæœ¬"
        exit 1
    fi
    
    update_system
    install_basics
    install_docker
    configure_firewall
    create_directories
    optimize_system
    install_monitoring
    setup_backup
    
    log_info "âœ… Lighthouse æœåŠ¡å™¨åˆå§‹åŒ–å®Œæˆï¼"
    log_info "è¯·é‡æ–°ç™»å½•ä»¥ä½¿Dockerç”¨æˆ·ç»„ç”Ÿæ•ˆ"
    log_info "ç„¶åè¿è¡Œ: cd /opt/targetmanage && git clone your-repo ."
}

# é”™è¯¯å¤„ç†
trap 'log_error "åˆå§‹åŒ–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯"' ERR

main "$@"
```

### Lighthouse éƒ¨ç½²è„šæœ¬

åˆ›å»º `scripts/lighthouse/deploy-lighthouse.sh`ï¼š

```bash
#!/bin/bash
# Lighthouse ä¸“ç”¨éƒ¨ç½²è„šæœ¬

set -e

GREEN='\033[0;32m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
NC='\033[0m'

log_info() {
    echo -e "${GREEN}[INFO]${NC} $1"
}

log_warn() {
    echo -e "${YELLOW}[WARN]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# æ£€æŸ¥èµ„æºä½¿ç”¨æƒ…å†µ
check_resources() {
    log_info "æ£€æŸ¥ç³»ç»Ÿèµ„æº..."
    
    # æ£€æŸ¥å†…å­˜
    TOTAL_MEM=$(free -m | awk 'NR==2{printf "%.0f", $2}')
    if [ $TOTAL_MEM -lt 3500 ]; then
        log_warn "å†…å­˜ä¸è¶³4GBï¼Œå»ºè®®å‡çº§å¥—é¤"
    fi
    
    # æ£€æŸ¥ç£ç›˜ç©ºé—´
    DISK_USAGE=$(df / | awk 'NR==2{print $5}' | sed 's/%//')
    if [ $DISK_USAGE -gt 80 ]; then
        log_warn "ç£ç›˜ä½¿ç”¨ç‡è¶…è¿‡80%ï¼Œè¯·æ¸…ç†ç©ºé—´"
    fi
    
    log_info "ç³»ç»Ÿèµ„æºæ£€æŸ¥å®Œæˆ"
}

# æ›´æ–°ä»£ç 
update_code() {
    log_info "æ›´æ–°ä»£ç ..."
    git fetch origin
    git reset --hard origin/main
}

# å¤‡ä»½æ•°æ®åº“
backup_database() {
    log_info "å¤‡ä»½æ•°æ®åº“..."
    if docker ps | grep -q targetmanage_postgres_lighthouse; then
        /opt/targetmanage/backup.sh
    else
        log_warn "æ•°æ®åº“å®¹å™¨æœªè¿è¡Œï¼Œè·³è¿‡å¤‡ä»½"
    fi
}

# æ„å»ºé•œåƒ (ä¼˜åŒ–ç‰ˆ)
build_images() {
    log_info "æ„å»ºDockeré•œåƒ..."
    
    # æ¸…ç†æ—§é•œåƒé‡Šæ”¾ç©ºé—´
    docker image prune -f
    
    # æ„å»ºåç«¯
    docker-compose -f docker-compose.lighthouse.yml build backend
    
    # æ„å»ºå‰ç«¯
    docker-compose -f docker-compose.lighthouse.yml build frontend
    
    log_info "é•œåƒæ„å»ºå®Œæˆ"
}

# å¯åŠ¨æœåŠ¡
start_services() {
    log_info "å¯åŠ¨æœåŠ¡..."
    
    # åœæ­¢ç°æœ‰æœåŠ¡
    docker-compose -f docker-compose.lighthouse.yml down
    
    # å¯åŠ¨æ•°æ®åº“æœåŠ¡
    docker-compose -f docker-compose.lighthouse.yml up -d postgres redis
    
    # ç­‰å¾…æ•°æ®åº“å¯åŠ¨
    sleep 10
    
    # æ‰§è¡Œæ•°æ®åº“è¿ç§»
    docker-compose -f docker-compose.lighthouse.yml run --rm backend alembic upgrade head
    
    # å¯åŠ¨æ‰€æœ‰æœåŠ¡
    docker-compose -f docker-compose.lighthouse.yml up -d
    
    log_info "æœåŠ¡å¯åŠ¨å®Œæˆ"
}

# å¥åº·æ£€æŸ¥
health_check() {
    log_info "æ‰§è¡Œå¥åº·æ£€æŸ¥..."
    
    sleep 30
    
    # æ£€æŸ¥åç«¯æœåŠ¡
    if curl -f http://localhost:8000/health > /dev/null 2>&1; then
        log_info "âœ… åç«¯æœåŠ¡æ­£å¸¸"
    else
        log_error "âŒ åç«¯æœåŠ¡å¼‚å¸¸"
        return 1
    fi
    
    # æ£€æŸ¥å‰ç«¯æœåŠ¡
    if curl -f http://localhost:3000 > /dev/null 2>&1; then
        log_info "âœ… å‰ç«¯æœåŠ¡æ­£å¸¸"
    else
        log_error "âŒ å‰ç«¯æœåŠ¡å¼‚å¸¸"
        return 1
    fi
    
    log_info "æ‰€æœ‰æœåŠ¡å¥åº·æ£€æŸ¥é€šè¿‡"
}

# æ¸…ç†èµ„æº
cleanup() {
    log_info "æ¸…ç†ç³»ç»Ÿèµ„æº..."
    
    # æ¸…ç†Dockerèµ„æº
    docker system prune -f
    
    # æ¸…ç†æ—¥å¿— (ä¿ç•™æœ€è¿‘7å¤©)
    find /opt/targetmanage/logs -name "*.log" -mtime +7 -delete
    
    log_info "èµ„æºæ¸…ç†å®Œæˆ"
}

# æ˜¾ç¤ºæœåŠ¡çŠ¶æ€
show_status() {
    log_info "=== æœåŠ¡çŠ¶æ€ ==="
    docker-compose -f docker-compose.lighthouse.yml ps
    
    log_info "=== èµ„æºä½¿ç”¨æƒ…å†µ ==="
    docker stats --no-stream --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}"
    
    log_info "=== ç³»ç»Ÿèµ„æº ==="
    free -h
    df -h /
}

# ä¸»å‡½æ•°
main() {
    log_info "ğŸš€ å¼€å§‹ Lighthouse éƒ¨ç½²..."
    
    check_resources
    update_code
    backup_database
    build_images
    start_services
    
    if health_check; then
        log_info "âœ… éƒ¨ç½²æˆåŠŸï¼"
    else
        log_error "âŒ éƒ¨ç½²å¤±è´¥"
        exit 1
    fi
    
    cleanup
    show_status
    
    log_info "ğŸ‰ Lighthouse éƒ¨ç½²å®Œæˆï¼"
    log_info "è®¿é—®åœ°å€:"
    log_info "- å‰ç«¯: http://$(curl -s ifconfig.me)"
    log_info "- API: http://$(curl -s ifconfig.me):8000"
    log_info "- æ–‡æ¡£: http://$(curl -s ifconfig.me):8000/docs"
}

# é”™è¯¯å¤„ç†
trap 'log_error "éƒ¨ç½²è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯"' ERR

main "$@"
```

## ğŸ”§ ç¯å¢ƒå˜é‡é…ç½®

åˆ›å»º `backend/.env.lighthouse`ï¼š

```env
# Lighthouse è½»é‡éƒ¨ç½²é…ç½®

# åŸºç¡€é…ç½®
APP_NAME=ç›®æ ‡ç®¡ç†ç³»ç»Ÿ
VERSION=1.0.0
DEBUG=False
HOST=0.0.0.0
PORT=8000

# å®‰å…¨é…ç½®
SECRET_KEY=lighthouse-secret-key-change-this-in-production
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# æœ¬åœ°æ•°æ®åº“é…ç½®
DATABASE_URL=postgresql://postgres:lighthouse_db_password@postgres:5432/targetmanage
REDIS_URL=redis://redis:6379/0
REDIS_CACHE_TTL=3600

# è…¾è®¯äº‘æœåŠ¡é…ç½® (ä»…AIæœåŠ¡)
TENCENT_SECRET_ID=your-secret-id
TENCENT_SECRET_KEY=your-secret-key
TENCENT_REGION=ap-beijing

# COSé…ç½® (ç”¨äºæ–‡ä»¶å­˜å‚¨)
COS_BUCKET_NAME=targetmanage-lighthouse-bucket
COS_REGION=ap-beijing

# å¾®ä¿¡å°ç¨‹åºé…ç½®
WECHAT_APP_ID=your-wechat-app-id
WECHAT_APP_SECRET=your-wechat-app-secret

# è½»é‡åŒ–é…ç½®
MAX_FILE_SIZE=5242880  # 5MB (é™ä½æ–‡ä»¶å¤§å°é™åˆ¶)
UPLOAD_DIR=uploads
LOG_LEVEL=INFO

# æ€§èƒ½ä¼˜åŒ–é…ç½®
DB_POOL_SIZE=5         # é™ä½è¿æ¥æ± å¤§å°
DB_MAX_OVERFLOW=10
WORKER_PROCESSES=2     # é™åˆ¶workerè¿›ç¨‹æ•°

# CORSé…ç½®
ALLOWED_HOSTS=["*"]  # å¼€å‘é˜¶æ®µå…è®¸æ‰€æœ‰åŸŸå
```

è¿™æ ·é…ç½®åï¼Œä½ çš„ç›®æ ‡ç®¡ç†ç³»ç»Ÿå°±å¯ä»¥åœ¨è…¾è®¯äº‘è½»é‡åº”ç”¨æœåŠ¡å™¨ä¸Šä»¥æä½çš„æˆæœ¬è¿è¡Œï¼Œéå¸¸é€‚åˆä¸šåŠ¡éªŒè¯é˜¶æ®µä½¿ç”¨ï¼

<function_calls>
<invoke name="todo_write">
<parameter name="merge">true
